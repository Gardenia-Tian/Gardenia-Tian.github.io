{"title":"源码编译pytorch踩坑记录","uid":"1d5abbd0f9937fba3b7aa81363ed1eab","slug":"源码编译pytorch踩坑记录","date":"2023-03-06T01:28:00.000Z","updated":"2023-03-08T08:38:07.539Z","comments":true,"path":"api/articles/源码编译pytorch踩坑记录.json","keywords":null,"cover":"https://github.com/pytorch/pytorch/blob/master/docs/source/_static/img/pytorch-logo-dark.png","content":"<h1>源码编译Pytorch踩坑记录</h1>\n<h3 id=\"获取pytorch源码\">获取pytorch源码</h3>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">conda <span class=\"token function\">install</span> mkl mkl-include\n<span class=\"token comment\"># CUDA only: Add LAPACK support for the GPU if needed</span>\nconda <span class=\"token function\">install</span> <span class=\"token parameter variable\">-c</span> pytorch magma-cuda113  <span class=\"token comment\"># or the magma-cuda* that matches your CUDA version from https://anaconda.org/pytorch/repo</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span></span></code></pre>\n<p>这一步都还没有什么问题, 接下来按照官网的指南执行</p>\n<h3 id=\"install-pytorch\">Install Pytorch</h3>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">CMAKE_PREFIX_PATH</span><span class=\"token operator\">=</span><span class=\"token variable\">$&#123;CONDA_PREFIX<span class=\"token operator\">:-</span>\"$(dirname $(which conda))<span class=\"token operator\">/</span>..<span class=\"token operator\">/</span>\"&#125;</span>\npython setup.py develop<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n<p>开始报错</p>\n<h4 id=\"error-inlining-failed-in-call-to-always-inline-mm256-set1-ps-target-specific-option-mismatch\">error: inlining failed in call to always_inline ‘_mm256_set1_ps’: target specific option mismatch</h4>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">CFLAGS</span><span class=\"token operator\">=</span><span class=\"token string\">\"-mfma\"</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>重新编译一遍发现这个错误不见了, 但是类似的还在,如<code>error: inlining failed in call to always_inline ‘_mm256_abs_epi16’: target specific option mismatch</code>. 所以感觉这个问题不是根本问题, 继续检索错误文件, 发现了这个问题<code>cc: error: /arch:AVX512: No such file or directory</code>.感觉这个地方才是本质问题, 所以先看这里, 参考<a href=\"https://stackoverflow.com/questions/57043592/compilation-error-for-avx512-is-it-a-gcc-issue\">这篇文章</a>, 尝试以下指令</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">CFLAGS</span><span class=\"token operator\">=</span><span class=\"token string\">\"-mavx512f\"</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>重新编译发现错误变少了, 但是<code>cc: error: /arch:AVX512: No such file or directory</code>这个报错还在</p>\n<p>尝试了很多方法都不行, 最后查了一下, 应该是电脑不支持avx512指令集, 可以用<code>cat /proc/cpuinfo | grep avx512</code>指令查看一下, 我的电脑上没有, 所以一直报错. 在set.py文件里可以看到这样的一段话</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>ATEN_AVX512_256=TRUE<br>\nATen AVX2 kernels can use 32 ymm registers, instead of the default 16.<br>\nThis option can be used if AVX512 doesn’t perform well on a machine.<br>\nThe FBGEMM library also uses AVX512_256 kernels on Xeon D processors,<br>\nbut it also has some (optimized) assembly code.</p></blockquote>\n<p>把这个环境变量改成false试了一下好像也不行, 最后无奈换了个设备重新编译</p>\n<h3 id=\"error-use-of-fmt-before-deduction-of-auto\">error: use of ‘fmt::…’ before deduction of ‘auto’</h3>\n<p><img src=\"/post/image-20230307102419154.png\" alt=\"image-20230307102419154\"></p>\n<p>在新的设备上构建cmakelists的时候没有什么问题, 但是编译的时候一直报这个错. 看路径是third_party里面的fmt这个包的问题, 但是我进入到这个包目录下cmake, make, make install 都是没有问题的.</p>\n<p>最后是因为编译器版本的问题, 给gcc升级从6.5.0到8.4.0就可以了.</p>\n<h3 id=\"终极解决方案\">终极解决方案</h3>\n<p>中间还经历了各种奇奇怪怪的问题, 但是最后都是用这个方法一下子解决的. 看到github上有人和我遇到了同样问题, 最后是重新fetch最新代码解决的, 我就也重新fetch了一下, 然后代码直接覆盖掉了之前的所有更改, 什么都不用做就全部编译通过了. 所以记录一下, 以后遇到类似的问题记得先检查<code>git clone --recursive</code>有没有成功, 之后一定要确保是最新的代码.</p>\n","feature":true,"text":"源码编译Pytorch踩坑记录 获取pytorch源码 conda install mkl mkl-include # CUDA only: Add LAPACK support for the GPU if needed conda install -c pytorch mag...","link":"","photos":[],"count_time":{"symbolsCount":"1.7k","symbolsTime":"2 mins."},"categories":[{"name":"清浅集","slug":"清浅集","count":3,"path":"api/categories/清浅集.json"}],"tags":[{"name":"pytorch","slug":"pytorch","count":1,"path":"api/tags/pytorch.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\"><span class=\"toc-text\">源码编译Pytorch踩坑记录</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E8%8E%B7%E5%8F%96pytorch%E6%BA%90%E7%A0%81\"><span class=\"toc-text\">获取pytorch源码</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#install-pytorch\"><span class=\"toc-text\">Install Pytorch</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#error-inlining-failed-in-call-to-always-inline-mm256-set1-ps-target-specific-option-mismatch\"><span class=\"toc-text\">error: inlining failed in call to always_inline ‘_mm256_set1_ps’: target specific option mismatch</span></a></li></ol></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#error-use-of-fmt-before-deduction-of-auto\"><span class=\"toc-text\">error: use of ‘fmt::…’ before deduction of ‘auto’</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E7%BB%88%E6%9E%81%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88\"><span class=\"toc-text\">终极解决方案</span></a></li></ol></li></ol></li></ol>","author":{"name":"Gardenia","slug":"blog-author","avatar":"/features/profile.jpg","link":"/","description":"People love what other people are passionate about.","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"prev_post":{},"next_post":{"title":"Pytorch多Stream管理","uid":"a42a03a50c6532bb0083a5ae2b8230f6","slug":"Pytorch多Stream管理","date":"2023-02-28T12:59:48.000Z","updated":"2023-02-28T13:26:02.671Z","comments":true,"path":"api/articles/Pytorch多Stream管理.json","keywords":null,"cover":null,"text":"import shutil import torch import torch.nn as nn import torch.nn.functional as F class ModelBaseline(nn.Module): ​ def init(self, d, n=4): ​...","link":"","photos":[],"count_time":{"symbolsCount":"2.3k","symbolsTime":"2 mins."},"categories":[],"tags":[],"author":{"name":"Gardenia","slug":"blog-author","avatar":"/features/profile.jpg","link":"/","description":"People love what other people are passionate about.","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"feature":true}}