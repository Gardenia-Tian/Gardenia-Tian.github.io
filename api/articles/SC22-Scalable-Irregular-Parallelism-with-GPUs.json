{"title":"SC22:Scalable Irregular Parallelism with GPUs","uid":"e9e2dbc3ab9cf522942297faeb7b28ca","slug":"SC22-Scalable-Irregular-Parallelism-with-GPUs","date":"2022-11-18T11:33:47.000Z","updated":"2022-11-19T09:38:05.562Z","comments":true,"path":"api/articles/SC22-Scalable-Irregular-Parallelism-with-GPUs.json","keywords":null,"cover":"https://cn.bing.com/th?id=OHR.WychwoodForest_EN-US6378774990_UHD.jpg&pid=hp&w=384&h=216&rs=1&c=4","content":"<h1 id=\"SC22-Scalable-Irregular-Parallelism-with-GPUs-Getting-CPUs-Out-of-the-Way\"><a href=\"#SC22-Scalable-Irregular-Parallelism-with-GPUs-Getting-CPUs-Out-of-the-Way\" class=\"headerlink\" title=\"SC22: Scalable Irregular Parallelism with GPUs: Getting CPUs Out of the Way\"></a>SC22: Scalable Irregular Parallelism with GPUs: Getting CPUs Out of the Way</h1><h2 id=\"背景知识\"><a href=\"#背景知识\" class=\"headerlink\" title=\"背景知识\"></a>背景知识</h2><p>在开始介绍本文的内容之前, 先进行一些扫盲, 介绍一下PGAS和单边内存操作</p>\n<h3 id=\"PGAS\"><a href=\"#PGAS\" class=\"headerlink\" title=\"PGAS\"></a>PGAS</h3><p>Partitioned Global Address Space (PGAS)</p>\n<p>共享内存模型扩展性差, 消息通信模型可编程性差, 有没有一个模型能在两者之间做出一个权衡? PGAS可以. PGAS是共享内存模型, 但是共享内存对线程具有亲和性.</p>\n<p><img src=\"/SC22-Scalable-Irregular-Parallelism-with-GPUs/image-20221119155749599.png\" alt=\"image-20221119155749599\"></p>\n<p>在分布式CPU系统上，从内存模型的角度来看，PGAS模型允许用户直接访问跨节点的共享内存的联合。用户可以访问全局指针和分布式数组，并将它们连接到单个分布式数据结构中。从编程模型的角度来看，PGAS语言使用SPMD方法，其中一组固定的进程在计算开始时一起开始，在计算结束时一起结束。</p>\n<h3 id=\"One-sides-memory-operation\"><a href=\"#One-sides-memory-operation\" class=\"headerlink\" title=\"One-sides memory operation\"></a>One-sides memory operation</h3><h4 id=\"One-sides-communication\"><a href=\"#One-sides-communication\" class=\"headerlink\" title=\"One-sides communication\"></a>One-sides communication</h4><p>先来看一下单边通信. 用MPI在RMA中的运行模式为例, 传统的MPI通信方式是MPI_Send和MPI_Recv, 这种模式也被称为双边通信：两个进程隐式地彼此同步。发送方和接收方都是通信的参与者, Send和Recv必须要相互匹配, 这种模式可能会造成通信的死锁或者性能下降. 在RMA的支持下, MPI提供了执行远程内存访问（RMA）的例程，也称为单边通信．其中进程可以访问其他进程上的数据，只要它在特殊的内存窗口中可用。本内容参考<a href=\"https://enccs.github.io/intermediate-mpi/one-sided-concepts/\">One-sided communication: concepts — Intermediate MPI (enccs.github.io)</a></p>\n<p>在并行框架或并行变成模型中, 各个进程之间是相互协作的, 每个worker或者每个process运行一部分的工作, 他们之间需要协调, 这就要用通信机制来完成. 通信的机制可以分成两种, <code>Cooperative</code>和<code>One sided</code>.</p>\n<ul>\n<li><p>Cooperative: 所有的参与者同同意并了解数据的传输</p>\n<p><img src=\"/SC22-Scalable-Irregular-Parallelism-with-GPUs/image-20221119103705866.png\" alt=\"image-20221119103705866\"></p>\n</li>\n<li><p>One-sided: 只有一个worker或process传输数据. 并行进程之间的单边操作包括远程内存读取和写入。优点是可以访问数据而无需等待另一个进程</p>\n<p><img src=\"/SC22-Scalable-Irregular-Parallelism-with-GPUs/image-20221119103756683.png\" alt=\"image-20221119103756683\"></p>\n</li>\n</ul>\n<h4 id=\"one-sides-memory-operation\"><a href=\"#one-sides-memory-operation\" class=\"headerlink\" title=\"one-sides memory operation\"></a>one-sides memory operation</h4><p>单边内存操作和单边通信是很类似的, 只不过从消息的收发变成了对内存的操作.</p>\n<h2 id=\"主要工作\"><a href=\"#主要工作\" class=\"headerlink\" title=\"主要工作\"></a>主要工作</h2><p>提出了Atos框架, 可以动态调度多节点GPU系统, 支持节点内和节点间PGAS轻量级单边内存操作, 用于在集群中的多个GPU之间进行异步执行。</p>\n<ol>\n<li><p>虽然直接从GPU到GPU的数据移动现在在现代系统上很普遍，但通信控制路径(包括通信准备和触发，可能的匹配和同步)即使在今天也通常在CPU上运行。本工作将通信控制路径移动到GPU, 并通过利用NVIDIA基于OpenSHMEM的NVSHMEM实现GPU之间真实的单边通信，该NVSHMEM将GPU内存映射到NIC(反之亦然)，以便远程GPU线程可以直接访问GPU内存，而无需本地或远程CPU参与。</p>\n</li>\n<li><p>传统上，在通信之前确保数据一致性是通过同步来自CPU的CUDA内核来实现的。这隐式地将数据一致性与同步结合在一起。为了避免这种耦合和由此产生的开销，ATOS实现了异步分布式队列，以确保数据一致性，并支持单边内核通信，而不需要任何同步。</p>\n</li>\n<li><p>传统上，只有在同步CUDA计算内核之后才会进行通信。</p>\n<ul>\n<li>大的,高GPU占用率的核函数的消息通信很延迟, 并且通信和计算的重叠很小</li>\n<li>小的,低GPU占用率的核函数的消息通信更加频繁, 并且通信和计算的重复比较大</li>\n</ul>\n<p>ATOS通过从核函数内部启用细粒度轻量级的通信, 实现更多的通信和计算的重叠. 小的通信更适合我们找到足够的计算来隐藏延迟.</p>\n</li>\n<li><p>在没有显式同步的情况下启用通信可以部署无同步算法，由于降低了同步成本，因此具有潜在的性能优势。相比之下，GPU上的传统BSP方法排除了使用无同步算法的可能性。</p>\n</li>\n<li><p>最后，我们的方法足够健壮，无需更改即可在具有两个不同互连族NVLink和InfiniBand(IB)的多GPU系统上高效工作。</p>\n</li>\n</ol>\n<p>本工作在NVlink和IB上都进行了测试, 结果表明, 使用NVLink互连，我们表明，我们的BFS和PageRank实现中的细粒度单边通信比其他框架具有更好的性能和可扩展性，因为它具有更好的延迟隐藏和更好的网络利用率。InfiniBand处理小消息的效率低于NVLink。为了优化InfiniBand的通信，ATOS实现了一个与应用程序代码并行运行的通信聚合器，它透明地将消息聚合在一起，并将它们以更大的消息包形式发送出去。我们表明，该聚合器有效地解决了由于细粒度的单边通信而导致的IB系统的带宽利用率不足的问题。在基于IB的系统上，我们的ATOS、BFS和PageRank实现在运行时和可伸缩性方面也优于其他框架。</p>\n<h2 id=\"背景介绍\"><a href=\"#背景介绍\" class=\"headerlink\" title=\"背景介绍\"></a>背景介绍</h2><ul>\n<li><p>批量同步通信模型(The bulk-synchronous communication model)是分布式CPU计算中最流行的模型之一. 通过将应用划分为大量的通信和计算阶段，批量同步并行(The bulk-synchronous communication model, BSP)模型生成了与现代节点间通信网络非常匹配的通信模式，现代节点间通信网络需要大量消息来实现峰值通信带宽。</p>\n</li>\n<li><p>许多分区全局地址空间(Partitioned Global Address Space, PGAS)语言(如UPC、UPC++和OpenSHMEM)的分布式实现成功地采用了另一种通信模型：发出许多独立的小型通信消息的模型. 在可以同时调度独立计算和通信的应用程序中，这种模式允许这些应用程序将通信延迟与计算时间重叠。小型单边通信消除了远程处理器同步的需要，从而降低了总体同步开销。与许多批量同步程序中变化较大的网络使用相比，小型通信通常可以均匀地分布在程序的运行时，从而平滑了网络使用。这些好处对于动态的、不规则的应用程序尤其显著，这些应用程序通常在不可预测的时间内进行细粒度的通信，并且没有预先确定的模式。</p>\n</li>\n<li><p>PGAS很适合这种动态的不规则的通信方式, 小粒度通信的主要缺点是带宽利用率较低，但尽管如此，有研究成果表明，即使在互连带宽有限的应用中，该通信模型也可以提供显著的性能优势。</p>\n</li>\n<li><p>PGAS在CPU上虽然用的挺多的, 但是在GPU上不是很常用, 因为</p>\n<ul>\n<li>在历史上，分布式系统中的其他GPU不能直接访问GPU内存。这排除了高效、细粒度的GPU到GPU的异步通信，因为这些通信必须通过CPU进行路由，从而增加了延迟。</li>\n<li>传统上, GPU的通信发生在核函数的前后, 如果放松这个限制会使数据一致性变得非常复杂, 单个大的核函数不能实现大量的overlap, 因为这样通信就变得更加的粗粒度, 而运行很多小的核函数通常会导致显著的内核启动开销和低GPU利用率.</li>\n<li>许多分布式算法中最流行的方式使用BSP模型, 这些模型对单边通信不能很好的映射.</li>\n</ul>\n<p>因此，分布式系统上的GPU主要以批量同步的方式用于计算和通信。然而，类似于PGAS的编程模型可能是一个更好的替代方案，特别是对于非常规应用程序：具有不同的通信和同步模式的应用程序。</p>\n</li>\n</ul>\n<h2 id=\"GPU上的PGAS编程模型\"><a href=\"#GPU上的PGAS编程模型\" class=\"headerlink\" title=\"GPU上的PGAS编程模型\"></a>GPU上的PGAS编程模型</h2><p>PGA编程模型以隐式通信(指针和数组引用)和显式的PUT和GET调用形式的单边通信原语为特色。这种方法非常适合现代的GPU到GPU通信机制，例如单个节点内的NVLink或PCIe。最近的进步使独立节点中的GPU能够直接执行进出InfiniBand网络的单边内存操作。PGAS和GPU都使用宽松的内存模型，该模型自动统一了排序、同步和原子操作的保证。</p>\n<p>以前也有一些这样的多GPU框架, 将GPU视为CPU的一个进程例如，Galois、PTASK和StarPU. 在这些框架中，每个GPU内核收集内核期间生成的所有通信，并在内核结束时批量发布, 这就导致必须在下述情况中做出一个权衡: 高GPU利用率但高延迟通信，或者低GPU利用率和低延迟通信。</p>\n<p>另一种选择是将每个GPU线程视为CPU进程的模拟，并允许每个GPU线程独立发出通信请求。但是, 一个GPU线程的粒度太细了, 协调数十万个并发线程的GPU任务是十分困难的. </p>\n<p>需求: 能够指定一组合适大小的线程, 作为指定的worker, 这一组线程之间的集体加载&#x2F;存储可以作为充分利用GPU存储器系统所必需的合并访问来发布。</p>\n<h2 id=\"Atos的设计模式\"><a href=\"#Atos的设计模式\" class=\"headerlink\" title=\"Atos的设计模式\"></a>Atos的设计模式</h2><p>PGAS编程模型的一个关键特征是通信和同步的解耦, ATOS以任务并行的方式编程，维护分布式任务队列。GPU worker从队列中获取任务，然后对其进行处理。如果新生成的任务属于本地进程，则将其添加到本地分布式队列中，否则将添加到所有者进程的远程分布式队列中。该程序一直运行，直到满足停止条件或整个分布式队列为空.</p>\n<p>开始具体介绍之前先明确一些术语:</p>\n<ul>\n<li>worker: 作为单个单元一起工作的一个或一组GPU线程(可选择利用共享内存)</li>\n<li>task: 在我们的系统中作为单个单元调度的一项或多项工作。任务可以由一个或多个数据元素组成。</li>\n<li>应用程序函数f()：处理每个任务的代码。每个应用程序函数都声明其运行所需的Worker大小。</li>\n</ul>\n<p>三个主要的可配置设计模式:</p>\n<ul>\n<li>内核实现策略：ATOS可以使用离散内核，也可以使用持久内核。在后一种情况下，只启动一个内核，该内核将一直驻留在GPU上，直到程序结束。这一策略虽然更为复杂，但更适合以内核启动开销为主的应用程序。</li>\n<li>队列结构：标准分布式队列与分布式优先级队列。在标准队列中，任务按FIFO顺序处理，而更复杂的优先级队列可以对标记为更高优先级的任务进行优先排序。正如我们稍后将展示的，此功能在异步设置中对于降低投机成本非常重要。</li>\n<li>worker size: 提供三个级别的size, thread, warp, CTA</li>\n</ul>\n","feature":true,"text":"SC22: Scalable Irregular Parallelism with GPUs: Getting CPUs Out of the Way背景知识在开始介绍本文的内容之前, 先进行一些扫盲, 介绍一下PGAS和单边内存操作 PGASPartitioned Global...","link":"","photos":[],"count_time":{"symbolsCount":"4.1k","symbolsTime":"4 mins."},"categories":[{"name":"知鱼集","slug":"知鱼集","count":1,"path":"api/categories/知鱼集.json"}],"tags":[{"name":"conference","slug":"conference","count":2,"path":"api/tags/conference.json"},{"name":"SC22","slug":"SC22","count":1,"path":"api/tags/SC22.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#SC22-Scalable-Irregular-Parallelism-with-GPUs-Getting-CPUs-Out-of-the-Way\"><span class=\"toc-text\">SC22: Scalable Irregular Parallelism with GPUs: Getting CPUs Out of the Way</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E8%83%8C%E6%99%AF%E7%9F%A5%E8%AF%86\"><span class=\"toc-text\">背景知识</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#PGAS\"><span class=\"toc-text\">PGAS</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#One-sides-memory-operation\"><span class=\"toc-text\">One-sides memory operation</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#One-sides-communication\"><span class=\"toc-text\">One-sides communication</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#one-sides-memory-operation\"><span class=\"toc-text\">one-sides memory operation</span></a></li></ol></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E4%B8%BB%E8%A6%81%E5%B7%A5%E4%BD%9C\"><span class=\"toc-text\">主要工作</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E8%83%8C%E6%99%AF%E4%BB%8B%E7%BB%8D\"><span class=\"toc-text\">背景介绍</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#GPU%E4%B8%8A%E7%9A%84PGAS%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B\"><span class=\"toc-text\">GPU上的PGAS编程模型</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#Atos%E7%9A%84%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F\"><span class=\"toc-text\">Atos的设计模式</span></a></li></ol></li></ol>","author":{"name":"Gardenia","slug":"blog-author","avatar":"/features/profile.jpg","link":"/","description":"阳光很好, 风也温柔","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"prev_post":{"title":"RDMA技术解读","uid":"0f7d08163e7123e37a424c72e1969a8c","slug":"RDMA技术解读","date":"2022-11-18T13:11:09.000Z","updated":"2022-11-18T13:46:16.671Z","comments":true,"path":"api/articles/RDMA技术解读.json","keywords":null,"cover":"https://img-blog.csdnimg.cn/1b2704ac4511494e8c4c1348d7ad4529.png","text":"RDMA技术解读本文参考技术蛋老师讲解RDMA的视频, It_server技术分享的视频侵删 传统Socket通信 用户将应用发送出去, 需要先到操作系统内核, 再到网络接口, 然后在接收方收到信息再次经过操作系统内核, 并在用户态分析数据. RDMA通信模式 绕过内核态, 直接...","link":"","photos":[],"count_time":{"symbolsCount":632,"symbolsTime":"1 mins."},"categories":[{"name":"清浅录","slug":"清浅录","count":4,"path":"api/categories/清浅录.json"}],"tags":[{"name":"体系结构","slug":"体系结构","count":2,"path":"api/tags/体系结构.json"},{"name":"网络","slug":"网络","count":1,"path":"api/tags/网络.json"}],"author":{"name":"Gardenia","slug":"blog-author","avatar":"/features/profile.jpg","link":"/","description":"阳光很好, 风也温柔","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"feature":true},"next_post":{"title":"Reproducibility Badges","uid":"3b2b2b9349423fdf4e4b627bcefbcbd6","slug":"Reproducibility-Badges","date":"2022-11-18T06:01:56.000Z","updated":"2022-11-18T11:43:21.116Z","comments":true,"path":"api/articles/Reproducibility-Badges.json","keywords":null,"cover":"https://www.acm.org/binaries/content/gallery/acm/publications/artifact-review-v1_1-badges/artifacts_evaluated_functional_v1_1.png","text":"Reproducibility Badges最近SC22正在如火如荼地进行, 作为一个科研小白, 我也有简单地远程围观这次会议. 在阅读SC会议的论文的时候, 我们会发现论文上总是有三个圆形的小标志, 所以不禁好奇这个是个什么东西, 经过一番查阅资料这里简单一下这个标志的含义. ...","link":"","photos":[],"count_time":{"symbolsCount":850,"symbolsTime":"1 mins."},"categories":[{"name":"清浅录","slug":"清浅录","count":4,"path":"api/categories/清浅录.json"}],"tags":[{"name":"conference","slug":"conference","count":2,"path":"api/tags/conference.json"},{"name":"SC","slug":"SC","count":1,"path":"api/tags/SC.json"}],"author":{"name":"Gardenia","slug":"blog-author","avatar":"/features/profile.jpg","link":"/","description":"阳光很好, 风也温柔","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}}}